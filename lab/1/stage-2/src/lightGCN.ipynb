{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fushen/micromamba/envs/vllm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按用户分组计算NDCG\n",
    "def compute_ndcg(group):\n",
    "    true_ratings = group[\"true\"].tolist()\n",
    "    pred_ratings = group[\"pred\"].tolist()\n",
    "    return ndcg_score([true_ratings], [pred_ratings], k=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对实验数据进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_PATH = os.path.dirname(\"../data/\")\n",
    "PREPROCESSED_DATA_PATH = os.path.join(DATA_PATH, \"lightGCN\")\n",
    "BOOK_DATA_PATH = os.path.join(PREPROCESSED_DATA_PATH, \"book\")\n",
    "# MOVIE_DATA_PATH = os.path.join(PREPROCESSED_DATA_PATH, \"movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Book</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Time</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1398478</td>\n",
       "      <td>1467022</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-03-29T12:48:35+08:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1398478</td>\n",
       "      <td>1777823</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-02-02T21:58:55+08:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1398478</td>\n",
       "      <td>1902628</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-31T15:57:58+08:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1398478</td>\n",
       "      <td>1878708</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-26T11:27:59+08:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1398478</td>\n",
       "      <td>4238362</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-21T13:04:15+08:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637249</th>\n",
       "      <td>4507957</td>\n",
       "      <td>1125186</td>\n",
       "      <td>4</td>\n",
       "      <td>2009-07-04T08:02:13+08:00</td>\n",
       "      <td>张爱玲,半生缘,爱情</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637250</th>\n",
       "      <td>4507957</td>\n",
       "      <td>1002299</td>\n",
       "      <td>5</td>\n",
       "      <td>2009-07-04T08:01:28+08:00</td>\n",
       "      <td>金庸,武侠,笑傲江湖</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637251</th>\n",
       "      <td>4507957</td>\n",
       "      <td>1001136</td>\n",
       "      <td>4</td>\n",
       "      <td>2009-07-04T07:55:17+08:00</td>\n",
       "      <td>彼得・潘,童话</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637252</th>\n",
       "      <td>4507957</td>\n",
       "      <td>1021615</td>\n",
       "      <td>5</td>\n",
       "      <td>2009-07-04T07:53:54+08:00</td>\n",
       "      <td>小王子,童话,经典</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637253</th>\n",
       "      <td>4507957</td>\n",
       "      <td>1962929</td>\n",
       "      <td>5</td>\n",
       "      <td>2009-06-29T22:13:37+08:00</td>\n",
       "      <td>爱情</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>637254 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           User     Book  Rate                       Time         Tag\n",
       "0       1398478  1467022     0  2011-03-29T12:48:35+08:00         NaN\n",
       "1       1398478  1777823     0  2011-02-02T21:58:55+08:00         NaN\n",
       "2       1398478  1902628     0  2011-01-31T15:57:58+08:00         NaN\n",
       "3       1398478  1878708     0  2011-01-26T11:27:59+08:00         NaN\n",
       "4       1398478  4238362     0  2011-01-21T13:04:15+08:00         NaN\n",
       "...         ...      ...   ...                        ...         ...\n",
       "637249  4507957  1125186     4  2009-07-04T08:02:13+08:00  张爱玲,半生缘,爱情\n",
       "637250  4507957  1002299     5  2009-07-04T08:01:28+08:00  金庸,武侠,笑傲江湖\n",
       "637251  4507957  1001136     4  2009-07-04T07:55:17+08:00     彼得・潘,童话\n",
       "637252  4507957  1021615     5  2009-07-04T07:53:54+08:00   小王子,童话,经典\n",
       "637253  4507957  1962929     5  2009-06-29T22:13:37+08:00          爱情\n",
       "\n",
       "[637254 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载原始书籍数据\n",
    "loaded_data = pd.read_csv(os.path.join(DATA_PATH, \"book_score.csv\"))\n",
    "loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookRatingDataset(Dataset):\n",
    "    def __init__(self, data, user_to_idx, book_to_idx):\n",
    "        self.data = data\n",
    "        self.user_to_idx = user_to_idx\n",
    "        self.book_to_idx = book_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        user = self.user_to_idx[row[\"User\"]]\n",
    "        book = self.book_to_idx[row[\"Book\"]]\n",
    "        rating = row[\"Rate\"].astype(\"float32\")\n",
    "        return user, book, rating\n",
    "    \n",
    "def create_id_mapping(id_list):\n",
    "    # 从ID列表中删除重复项并创建一个排序的列表\n",
    "    unique_ids = sorted(set(id_list))\n",
    "\n",
    "    # 创建将原始ID映射到连续索引的字典\n",
    "    id_to_idx = {id: idx for idx, id in enumerate(unique_ids, start=1)}\n",
    "\n",
    "    return id_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = loaded_data[\"User\"].unique()\n",
    "book_ids = loaded_data[\"Book\"].unique()\n",
    "\n",
    "user_to_idx = create_id_mapping(user_ids)\n",
    "book_to_idx = create_id_mapping(book_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data[\"user_map\"] = loaded_data[\"User\"].map(user_to_idx)\n",
    "loaded_data[\"book_map\"] = loaded_data[\"Book\"].map(book_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据集\n",
    "train_data, test_data = train_test_split(loaded_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# 过滤掉训练集中 Rate < 4 的数据\n",
    "train_data = train_data[train_data[\"Rate\"] >= 4]\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    BookRatingDataset(test_data, user_to_idx, book_to_idx),\n",
    "    batch_size=4096,\n",
    "    shuffle=False,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "# 将 train_data, test_data 转换为 user -> item 的字典\n",
    "train_data = train_data.groupby(\"user_map\")[\"book_map\"].apply(list).to_dict()\n",
    "test_data = test_data.groupby(\"user_map\")[\"book_map\"].apply(list).to_dict()\n",
    "\n",
    "# 写入 train.txt, test.txt\n",
    "# 每行格式为 user_id item_id_1 item_id_2 ...\n",
    "with open(os.path.join(BOOK_DATA_PATH, \"train.txt\"), \"w\") as f:\n",
    "    for user, items in train_data.items():\n",
    "        f.write(f\"{user} {' '.join(map(str, items))}\\n\")\n",
    "\n",
    "with open(os.path.join(BOOK_DATA_PATH, \"test.txt\"), \"w\") as f:\n",
    "    for user, items in test_data.items():\n",
    "        f.write(f\"{user} {' '.join(map(str, items))}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载 LightGCN 的 Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightGCN_model import LightGCN, Loader, BPRLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;30;43mloading [../data/lightGCN/book]\u001b[0m\n",
      "148151 interactions for training\n",
      "318627 interactions for testing\n",
      "Dataset Sparsity : 0.08793162560611256\n",
      "Dataset is ready to go\n"
     ]
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    \"bpr_batch_size\": 2048,\n",
    "    \"latent_dim_rec\": 64,\n",
    "    \"lightGCN_n_layers\": 3,\n",
    "    \"dropout\": 0,\n",
    "    \"keep_prob\": 0.6,\n",
    "    \"A_n_fold\": 100,\n",
    "    \"test_u_batch_size\": 100,\n",
    "    \"multicore\": 0,\n",
    "    \"lr\": 0.001,\n",
    "    \"decay\": 1e-4,\n",
    "    \"pretrain\": 0,\n",
    "    \"A_split\": False,\n",
    "    \"bigdata\": False,\n",
    "}\n",
    "\n",
    "data_loader = Loader(CONFIG, BOOK_DATA_PATH, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练 LightGCN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading adjacency matrix\n",
      "lgn is already to go(dropout:0)\n"
     ]
    }
   ],
   "source": [
    "model = LightGCN(CONFIG, data_loader).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils for training\n",
    "def uniform_sample(dataset: Loader):\n",
    "    user_num = dataset.trainDataSize\n",
    "    users = np.random.randint(0, dataset.n_users, user_num)\n",
    "    all_pos = dataset.allPos\n",
    "    S = []\n",
    "    for _, user in enumerate(users):\n",
    "        pos_for_user = all_pos[user]\n",
    "        if len(pos_for_user) == 0:\n",
    "            continue\n",
    "        pos_index = np.random.randint(0, len(pos_for_user))\n",
    "        pos_item = pos_for_user[pos_index]\n",
    "        while True:\n",
    "            neg_item = np.random.randint(0, dataset.m_items)\n",
    "            if neg_item not in pos_for_user:\n",
    "                break\n",
    "        S.append([user, pos_item, neg_item])\n",
    "    return np.asarray(S)\n",
    "\n",
    "\n",
    "def shuffle(*arrays, **kwargs):\n",
    "    require_indices = kwargs.get(\"require_indices\", False)\n",
    "\n",
    "    if len(set(len(x) for x in arrays)) != 1:\n",
    "        raise ValueError(\"All inputs to shuffle must have the same length.\")\n",
    "\n",
    "    shuffle_indices = np.random.permutation(len(arrays[0]))\n",
    "    np.random.shuffle(shuffle_indices)\n",
    "\n",
    "    if len(arrays) == 1:\n",
    "        result = arrays[0][shuffle_indices]\n",
    "    else:\n",
    "        result = tuple(x[shuffle_indices] for x in arrays)\n",
    "\n",
    "    if require_indices:\n",
    "        return result, shuffle_indices\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def minibatch(*tensors, **kwargs):\n",
    "    batch_size = kwargs.get(\"batch_size\", CONFIG[\"bpr_batch_size\"])\n",
    "\n",
    "    if len(tensors) == 1:\n",
    "        tensor = tensors[0]\n",
    "        for i in range(0, len(tensor), batch_size):\n",
    "            yield tensor[i : i + batch_size]\n",
    "    else:\n",
    "        for i in range(0, len(tensors[0]), batch_size):\n",
    "            yield tuple(x[i : i + batch_size] for x in tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 5/40 [00:25<02:49,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5, Average Loss: 0.593530935900552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 10/40 [00:46<02:10,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10, Average Loss: 0.5475959283964974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 15/40 [01:08<01:48,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15, Average Loss: 0.497956639954022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 20/40 [01:31<01:33,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20, Average Loss: 0.45337486777986796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 25/40 [01:53<01:07,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #25, Average Loss: 0.4211744810853686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 30/40 [02:16<00:46,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #30, Average Loss: 0.3941047808953694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 35/40 [02:42<00:25,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #35, Average Loss: 0.37099391094275885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [03:05<00:00,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #40, Average Loss: 0.3550679794379643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 40\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    bpr = BPRLoss(model, CONFIG)\n",
    "    S = uniform_sample(data_loader)\n",
    "\n",
    "    users = torch.Tensor(S[:, 0]).long().to(device)\n",
    "    pos_items = torch.Tensor(S[:, 1]).long().to(device)\n",
    "    neg_items = torch.Tensor(S[:, 2]).long().to(device)\n",
    "\n",
    "    users, pos_items, neg_items = shuffle(users, pos_items, neg_items)\n",
    "\n",
    "    total_batch = len(users) // CONFIG[\"bpr_batch_size\"] + 1\n",
    "\n",
    "    avg_loss = 0.0\n",
    "\n",
    "    for _, (batch_users, batch_pos, batch_neg) in enumerate(\n",
    "        minibatch(users, pos_items, neg_items)\n",
    "    ):\n",
    "        cri = bpr.stageOne(batch_users, batch_pos, batch_neg)\n",
    "        avg_loss += cri\n",
    "    avg_loss /= total_batch\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch #{epoch + 1}, Average Loss: {avg_loss}\")\n",
    "        # results = []\n",
    "        # with torch.no_grad():\n",
    "        #     for user_ids, item_ids, true_ratings in test_dataloader:\n",
    "        #         user_ids = user_ids.to(device)\n",
    "        #         item_ids = item_ids.to(device)\n",
    "        #         true_ratings = true_ratings.to(device)\n",
    "\n",
    "        #         ratings = model.getUsersRating(user_ids)\n",
    "        #         pred_ratings = ratings[torch.arange(len(ratings)), item_ids]\n",
    "\n",
    "        #         user_ids_np = user_ids.long().cpu().numpy().reshape(-1, 1)\n",
    "        #         pred_ratings_np = pred_ratings.cpu().numpy().reshape(-1, 1)\n",
    "        #         true_ratings_np = true_ratings.cpu().numpy().reshape(-1, 1)\n",
    "\n",
    "        #         results.append(\n",
    "        #             np.column_stack((user_ids_np, pred_ratings_np, true_ratings_np))\n",
    "        #         )\n",
    "                \n",
    "        #     results_df = pd.DataFrame(\n",
    "        #         np.vstack(results), columns=[\"user\", \"pred\", \"true\"]\n",
    "        #     )\n",
    "        #     results_df[\"user\"] = results_df[\"user\"].astype(int)\n",
    "\n",
    "        #     ndcg_scores = results_df.groupby(\"user\").apply(compute_ndcg)\n",
    "        #     avg_ndcg = ndcg_scores.mean()\n",
    "\n",
    "        #     print(f\"Epoch #{epoch}, Average Loss: {avg_loss}, Average NDCG: {avg_ndcg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f\"../model/lightgcn_{NUM_EPOCHS}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "model = torch.load(f\"../model/lightgcn_{epochs}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:24<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG: 0.7216618278765373\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for user_ids, item_ids, true_ratings in tqdm(\n",
    "        test_dataloader, total=len(test_dataloader)\n",
    "    ):\n",
    "        user_ids = user_ids.to(device)\n",
    "        item_ids = item_ids.to(device)\n",
    "        true_ratings = true_ratings.to(device)\n",
    "\n",
    "        ratings = model.getUsersRating(user_ids)\n",
    "        pred_ratings = ratings[torch.arange(len(ratings)), item_ids]\n",
    "\n",
    "        user_ids_np = user_ids.long().cpu().numpy().reshape(-1, 1)\n",
    "        pred_ratings_np = pred_ratings.cpu().numpy().reshape(-1, 1)\n",
    "        true_ratings_np = true_ratings.cpu().numpy().reshape(-1, 1)\n",
    "\n",
    "        test_results.append(\n",
    "            np.column_stack((user_ids_np, pred_ratings_np, true_ratings_np))\n",
    "        )\n",
    "\n",
    "test_results_df = pd.DataFrame(\n",
    "    np.vstack(test_results), columns=[\"user\", \"pred\", \"true\"]\n",
    ")\n",
    "test_results_df[\"user\"] = test_results_df[\"user\"].astype(int)\n",
    "\n",
    "ndcg_scores = test_results_df.groupby(\"user\").apply(compute_ndcg)\n",
    "avg_ndcg = ndcg_scores.mean()\n",
    "\n",
    "print(f\"Average NDCG: {avg_ndcg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3326</td>\n",
       "      <td>0.888533</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1393</td>\n",
       "      <td>0.934420</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1522</td>\n",
       "      <td>0.652645</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2534</td>\n",
       "      <td>0.761625</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3671</td>\n",
       "      <td>0.818293</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315387</th>\n",
       "      <td>229</td>\n",
       "      <td>0.989655</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315388</th>\n",
       "      <td>4304</td>\n",
       "      <td>0.871210</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315389</th>\n",
       "      <td>2268</td>\n",
       "      <td>0.870233</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315390</th>\n",
       "      <td>2880</td>\n",
       "      <td>0.980854</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315391</th>\n",
       "      <td>3707</td>\n",
       "      <td>0.876468</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315392 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user      pred  true\n",
       "0       3326  0.888533   4.0\n",
       "1       1393  0.934420   4.0\n",
       "2       1522  0.652645   4.0\n",
       "3       2534  0.761625   0.0\n",
       "4       3671  0.818293   0.0\n",
       "...      ...       ...   ...\n",
       "315387   229  0.989655   4.0\n",
       "315388  4304  0.871210   0.0\n",
       "315389  2268  0.870233   0.0\n",
       "315390  2880  0.980854   4.0\n",
       "315391  3707  0.876468   5.0\n",
       "\n",
       "[315392 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_df.to_csv(\"../output/lightgcn_results.csv\", index=False)\n",
    "test_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG: 0.7339513305770557\n"
     ]
    }
   ],
   "source": [
    "# 读取预测结果并计算平均 NDCG\n",
    "loaded_results = pd.read_csv(\"../output/lightgcn_results.csv\")\n",
    "ndcg_scores = loaded_results.groupby(\"user\").apply(compute_ndcg)\n",
    "avg_ndcg = ndcg_scores.mean()\n",
    "\n",
    "print(f\"Average NDCG: {avg_ndcg}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
